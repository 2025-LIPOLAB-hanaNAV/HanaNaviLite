# syntax=docker/dockerfile:1.6

FROM ollama/ollama:latest

# List of models to bake into the image. Adjust as needed.
# Build-arg can override, otherwise default to two models.
ARG OLLAMA_MODELS="gemma3:12b-it-qat llama3.1:8b-instruct"
ENV OLLAMA_MODELS=${OLLAMA_MODELS}

# Pre-pull models during build by starting a temporary ollama serve
RUN bash -lc 'set -euo pipefail; \
    ollama serve & \
    pid=$!; \
    # Give server time to start
    for i in $(seq 1 30); do \
      sleep 1; \
      curl -sf http://127.0.0.1:11434/ >/dev/null && break || true; \
    done; \
    for m in $OLLAMA_MODELS; do \
      echo "Pulling $m"; \
      ollama pull "$m" || exit 1; \
    done; \
    # Stop server
    kill $pid || true; \
    wait $pid || true'

# Default serve
EXPOSE 11434
CMD ["ollama", "serve"]
