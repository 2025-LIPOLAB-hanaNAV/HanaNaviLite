# HanaNaviLite Docker ì‚¬ìš©ë²• ê°€ì´ë“œ

## ê°œìš”

HanaNaviLiteëŠ” ë‘ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ Ollamaë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
1. **ë¡œì»¬ ì„œë²„ì˜ ê¸°ì¡´ Ollama API ì‚¬ìš©** (ì¶”ì²œ)
2. **Docker ì»¨í…Œì´ë„ˆë¡œ Ollama ì‹¤í–‰**

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ì‚¬ì „ ì¤€ë¹„

1. Dockerì™€ Docker Compose ì„¤ì¹˜
2. NVIDIA GPU ì‚¬ìš©ì‹œ nvidia-docker ì„¤ì¹˜ (ì„ íƒì )

### ë°©ë²• 1: ë¡œì»¬ Ollama API ì‚¬ìš© (ì¶”ì²œ)

#### 1.1 ë¡œì»¬ Ollama ì„¤ì •

```bash
# ë¡œì»¬ì— Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ë©´
ollama serve  # Ollama ì„œë²„ ì‹œì‘

# í•„ìš”í•œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull gemma3:12b-it-qat
```

#### 1.2 Docker Composeë¡œ HanaNaviLite ì‹¤í–‰

```bash
# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ë§Œ ì‹¤í–‰ (ë¡œì»¬ Ollama ì‚¬ìš©)
docker-compose up -d hananavilite redis

# ë˜ëŠ” ëª¨ë“  ì„œë¹„ìŠ¤ ì‹¤í–‰ (Ollama ì»¨í…Œì´ë„ˆ ì œì™¸)
docker-compose up -d
```

### ë°©ë²• 2: Ollama ì»¨í…Œì´ë„ˆ ì‚¬ìš©

#### 2.1 í™˜ê²½ë³€ìˆ˜ ì„¤ì •

```bash
# docker-compose.ymlì—ì„œ Ollama URL ë³€ê²½
# 16ë²ˆì§¸ ì¤„ì„ ì£¼ì„ ì²˜ë¦¬í•˜ê³  17ë²ˆì§¸ ì¤„ ì£¼ì„ í•´ì œ:
# - OLLAMA_BASE_URL=http://host.docker.internal:11434  # ë¡œì»¬ Ollama ì‚¬ìš©ì‹œ
- OLLAMA_BASE_URL=http://ollama:11434  # Ollama ì»¨í…Œì´ë„ˆ ì‚¬ìš©ì‹œ
```

#### 2.2 Ollama ì»¨í…Œì´ë„ˆ í¬í•¨ ì‹¤í–‰

```bash
# GPUê°€ ìˆëŠ” ê²½ìš°
docker-compose --profile ollama-container up -d

# CPUë§Œ ì‚¬ìš©í•˜ëŠ” ê²½ìš° (docker-compose.ymlì—ì„œ GPU ì„¤ì • ì œê±° í›„)
docker-compose --profile ollama-container up -d
```

#### 2.3 Ollama ì»¨í…Œì´ë„ˆì— ëª¨ë¸ ì„¤ì¹˜

```bash
# Ollama ì»¨í…Œì´ë„ˆì— ì ‘ì†
docker exec -it hananavilite-ollama ollama pull gemma3:12b-it-qat
```

## ğŸ”§ ì„¤ì • ì˜µì…˜

### í™˜ê²½ë³€ìˆ˜

ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ë¥¼ í†µí•´ ì„¤ì •ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```yaml
environment:
  - OLLAMA_BASE_URL=http://localhost:11434       # Ollama ì„œë²„ URL
  - LLM_MODEL=gemma3:12b-it-qat                  # ì‚¬ìš©í•  LLM ëª¨ë¸
  - EMBEDDING_MODEL=dragonkue/snowflake-arctic-embed-l-v2.0-ko  # ì„ë² ë”© ëª¨ë¸
  - LLM_TEMPERATURE=0.1                          # LLM ì˜¨ë„ (ì°½ì˜ì„±)
  - LLM_MAX_TOKENS=2048                          # ìµœëŒ€ í† í° ìˆ˜
  - DATABASE_URL=sqlite:///data/hananavilite.db  # ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ
  - LOG_LEVEL=INFO                               # ë¡œê·¸ ë ˆë²¨
```

### ë³¼ë¥¨ ë§ˆìš´íŠ¸

```yaml
volumes:
  - ./data:/app/data        # ë°ì´í„°ë² ì´ìŠ¤ ë° ì¸ë±ìŠ¤
  - ./models:/app/models    # AI ëª¨ë¸ ìºì‹œ
  - ./uploads:/app/uploads  # ì—…ë¡œë“œëœ íŒŒì¼
  - ./logs:/app/logs        # ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸
```

## ğŸ“š ìƒì„¸ ì‚¬ìš©ë²•

### 1. ê°œë°œ í™˜ê²½ ì„¤ì •

```bash
# ê°œë°œìš© ì‹¤í–‰ (ì½”ë“œ ë³€ê²½ ìë™ ë°˜ì˜)
docker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d
```

### 2. í”„ë¡œë•ì…˜ í™˜ê²½ ë°°í¬

```bash
# í”„ë¡œë•ì…˜ ë¹Œë“œ ë° ì‹¤í–‰
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d
```

### 3. ë¡œê·¸ í™•ì¸

```bash
# ì „ì²´ ë¡œê·¸ í™•ì¸
docker-compose logs -f

# íŠ¹ì • ì„œë¹„ìŠ¤ ë¡œê·¸ í™•ì¸
docker-compose logs -f hananavilite
docker-compose logs -f ollama
```

### 4. ìƒíƒœ í™•ì¸

```bash
# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
docker-compose ps

# í—¬ìŠ¤ ì²´í¬
curl http://localhost:8001/api/v1/health
```

## ğŸ›  íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤

#### 1. Ollama ì—°ê²° ì‹¤íŒ¨

**ë¬¸ì œ**: `Connection refused to http://localhost:11434`

**í•´ê²°ë°©ë²•**:
- ë¡œì»¬ Ollama ì‚¬ìš©ì‹œ: `ollama serve` ì‹¤í–‰ í™•ì¸
- ì»¨í…Œì´ë„ˆ ì‚¬ìš©ì‹œ: `docker-compose logs ollama` í™•ì¸

#### 2. ì„ë² ë”© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜

**ë¬¸ì œ**: `dragonkue/snowflake-arctic-embed-l-v2.0-ko` ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨

**í•´ê²°ë°©ë²•**:
```bash
# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ
docker exec -it hananavilite-app python -c "
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('dragonkue/snowflake-arctic-embed-l-v2.0-ko')
"
```

#### 3. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±

**ë¬¸ì œ**: CUDA out of memory

**í•´ê²°ë°©ë²•**:
```yaml
# docker-compose.ymlì—ì„œ ë©”ëª¨ë¦¬ ì œí•œ ì¶”ê°€
deploy:
  resources:
    limits:
      memory: 8G
    reservations:
      devices:
        - driver: nvidia
          count: 1
          capabilities: [gpu]
```

#### 4. í¬íŠ¸ ì¶©ëŒ

**ë¬¸ì œ**: Port already in use

**í•´ê²°ë°©ë²•**:
```yaml
# docker-compose.ymlì—ì„œ í¬íŠ¸ ë³€ê²½
ports:
  - "8002:8001"  # í˜¸ìŠ¤íŠ¸ í¬íŠ¸ ë³€ê²½
```

## ğŸ” ëª¨ë‹ˆí„°ë§

### 1. ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§

```bash
# ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
docker stats

# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸
docker system df
```

### 2. ì• í”Œë¦¬ì¼€ì´ì…˜ ëª¨ë‹ˆí„°ë§

```bash
# API ìƒíƒœ í™•ì¸
curl -s http://localhost:8001/api/v1/health | jq

# ì„ë² ë”© ëª¨ë¸ ìƒíƒœ í™•ì¸
curl -s http://localhost:8001/api/v1/health | jq '.embedding_model'
```

## ğŸ”„ ì—…ë°ì´íŠ¸ ë° ë°±ì—…

### ì—…ë°ì´íŠ¸

```bash
# ìµœì‹  ì½”ë“œë¡œ ì—…ë°ì´íŠ¸
git pull
docker-compose build --no-cache
docker-compose up -d
```

### ë°±ì—…

```bash
# ë°ì´í„° ë°±ì—…
tar -czf backup_$(date +%Y%m%d).tar.gz data/

# ë³µì›
tar -xzf backup_YYYYMMDD.tar.gz
```

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ë©´:
1. ë¡œê·¸ í™•ì¸: `docker-compose logs -f`
2. ìƒíƒœ í™•ì¸: `docker-compose ps`
3. í—¬ìŠ¤ì²´í¬: `curl http://localhost:8001/api/v1/health`

ì¶”ê°€ ì§€ì›ì´ í•„ìš”í•˜ë©´ GitHub Issuesë¥¼ í†µí•´ ë¬¸ì˜í•´ ì£¼ì„¸ìš”.